{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "\n",
        "\n",
        "\n",
        "A parameter is a value that controls a model’s behavior and is learned from data during training.\n",
        "Examples: weights and biases in a neural network, coefficients in linear regression.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "2. What is correlation?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Correlation measures the strength & direction of a linear relationship between two variables. It is usually represented by a correlation coefficient (e.g., Pearson’s r), which ranges from -1 to +1.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "3. What does negative correlation mean?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Negative correlation means as one variable increases, the other tends to decrease. Pearson r < 0 (e.g., r = -0.8 is strong negative).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "4. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Machine Learning (ML) is the field of designing algorithms that learn patterns from data and make predictions or decisions. Main components:\n",
        "\n",
        "\n",
        "\n",
        "Data (features and labels)\n",
        "\n",
        "Model/Algorithm (e.g., linear regression, decision trees, neural networks)\n",
        "\n",
        "Objective/Loss function (what we optimize)\n",
        "\n",
        "Optimizer/training procedure (how parameters are updated)\n",
        "\n",
        "Evaluation/metrics (accuracy, RMSE, etc.)\n",
        "\n",
        "Preprocessing/feature engineering (scaling, encoding, handling missing values)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "5. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Loss quantifies the model’s prediction error on data (training/validation). Lower loss usually means better fit. But judge with:\n",
        "\n",
        "\n",
        "\n",
        "Validation/test loss (not just training) to detect overfitting.\n",
        "\n",
        "Appropriate metric for problem (e.g., accuracy, F1 for classification; MSE, MAE for regression).\n",
        "\n",
        "Compare to baseline models. So loss is a signal but must be interpreted in context.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "6. What are continuous and categorical variables?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Continuous variables: numeric values on a continuous scale (height, temperature, price).\n",
        "\n",
        "Categorical variables: discrete groups or labels (color: red/blue/green; country names). Can be nominal (no order) or ordinal (ordered).\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "7. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Common techniques:\n",
        "\n",
        "\n",
        "\n",
        "Label Encoding: map categories to integers (good for ordinal).\n",
        "\n",
        "One-Hot Encoding: create binary column per category (for nominal).\n",
        "\n",
        "Target / Mean Encoding: replace category with mean target value (use carefully to avoid leakage).\n",
        "\n",
        "Binary/Hash Encoding, Embedding (for high-cardinality categories in deep learning).\n",
        "Also handle rare categories and missing values.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "8. What do you mean by training and testing a dataset?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Training: fitting the model (learning parameters) on a subset of data.\n",
        "\n",
        "Testing (evaluation): measuring model performance on unseen data (test set) to estimate generalization."
      ],
      "metadata": {
        "id": "GMM84HX5bV_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is sklearn.preprocessing?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "sklearn.preprocessing is a module in scikit-learn that provides utilities for scaling, encoding, feature transformations and imputations (e.g., StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder, PolynomialFeatures).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "10. What is a Test set?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The test set is a portion of data held out from training and validation used only for the final performance assessment of the trained model. It simulates new/unseen data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "11. How do we split data for model fitting (training and testing) in Python?"
      ],
      "metadata": {
        "id": "TPKL3DqYb15g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assume X (features) and y (target) are ready\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Now split X_temp into validation and test sets\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(\"Train size:\", X_train.shape)\n",
        "print(\"Validation size:\", X_val.shape)\n",
        "print(\"Test size:\", X_test.shape)"
      ],
      "metadata": {
        "id": "y4yYYLUHeawh",
        "outputId": "debe6c8e-612e-4738-fad6-8fed9f9381d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3352103178.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Assume X (features) and y (target) are ready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Now split X_temp into validation and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How do you approach a Machine Learning problem?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Typical steps:\n",
        "\n",
        "\n",
        "-Define the problem & success metric.\n",
        "\n",
        "\n",
        "-Collect & inspect data (EDA).\n",
        "\n",
        "\n",
        "-Clean & preprocess data (handle missing values, encode, scale).\n",
        "\n",
        "\n",
        "-Feature engineering/selection.\n",
        "\n",
        "\n",
        "-Choose baseline models and evaluate (train/validation).\n",
        "\n",
        "\n",
        "- Tune hyperparameters / try stronger models.\n",
        "\n",
        "\n",
        "- Validate with cross-validation and final test set.\n",
        "\n",
        "\n",
        "-Deploy and monitor.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "13. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Exploratory Data Analysis (EDA) helps to:\n",
        "\n",
        "\n",
        "\n",
        "Understand distributions, outliers, correlations and missing values.\n",
        "\n",
        "Detect data quality issues and biases.\n",
        "\n",
        "Choose appropriate models, transformations, and features.\n",
        "Skipping EDA risks poor model performance and incorrect conclusions.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "14. What is correlation?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Correlation is a statistical measure that expresses the degree to which two variables move together. Pearson correlation measures linear relationship; Spearman measures monotonic relationship.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "15. What does negative correlation mean?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Negative correlation: when one variable increases, the other tends to decrease (correlation coefficient < 0).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "16. How can you find correlation between variables in Python?\n",
        "\n",
        "\n",
        "Use pandas and visualization:"
      ],
      "metadata": {
        "id": "LPAFdmX0cEYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "corr_matrix = df.corr()  # Pearson correlation by default"
      ],
      "metadata": {
        "id": "2Gnq4FGXcr8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Causation: changes in A directly cause changes in B.\n",
        "\n",
        "Correlation: A and B change together but not necessarily cause-effect; might be coincidental or due to a third factor.\n",
        "Example: Ice cream sales and drowning incidents are correlated (both rise in summer) but ice cream sales do not cause drownings — temperature (a confounder) causes both.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "18. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "An optimizer updates model parameters to minimize the loss function. Common types:\n",
        "\n",
        "\n",
        "\n",
        "Gradient Descent (Batch GD): uses full dataset gradient each update — stable but slow on large data.\n",
        "\n",
        "Stochastic Gradient Descent (SGD): uses one sample per update — noisy but can escape shallow minima.\n",
        "\n",
        "Mini-batch Gradient Descent: compromise using small batches.\n",
        "\n",
        "Momentum: adds velocity term to accelerate in relevant directions.\n",
        "\n",
        "AdaGrad: adapts learning rate per-parameter (good for sparse data).\n",
        "\n",
        "RMSprop: adaptive method that fixes AdaGrad’s decreasing lr issue.\n",
        "\n",
        "Adam: combines momentum and RMSprop — widely used, good default.\n",
        "Example: In Keras, optimizer='adam' uses Adam.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "19. What is sklearn.linear_model?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "sklearn.linear_model is a scikit-learn module with linear models like LinearRegression, LogisticRegression, Ridge, Lasso, SGDRegressor. It provides fit/predict APIs and regularization options.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "20. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.fit() trains the model by estimating parameters using training data. For scikit-learn models the required arguments are usually X (features) and y (target): model.fit(X_train, y_train). Some frameworks require extra args (e.g., epochs in Keras).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "21. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.predict() uses the trained model to produce predictions for given input features. Argument: X_new (feature matrix). Example: y_pred = model.predict(X_test).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "22. What are continuous and categorical variables?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "(Repeat) Continuous = numeric with many possible values (height, weight). Categorical = discrete labels (gender, city). See Q6.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "23. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Feature scaling rescales numeric features to a similar range. Methods: Standardization (zero mean, unit variance), Min-Max scaling (0–1). It helps algorithms that rely on distance or gradient (KNN, SVM, neural nets, gradient descent) to converge faster and behave properly.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "24. How do we perform scaling in Python?\n",
        "Use scikit-learn scalers:"
      ],
      "metadata": {
        "id": "EvUB-Atrcx32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "RiBR_Ns8dbus",
        "outputId": "0a1ad960-f5fc-43d5-efe0-a5ec398e838c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1787405782.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. What is sklearn.preprocessing?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " sklearn.preprocessing contains classes and functions for scaling, encoding, normalization, polynomial feature expansion, and other feature transforms (e.g., StandardScaler, OneHotEncoder, LabelEncoder, MinMaxScaler, Normalizer).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "26. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "(This question is repeated in image as well): Use train_test_split from scikit-learn. Example shown in Q11.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "27. Explain data encoding?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Data encoding = converting categorical/text data into numeric representations for ML. Common methods:\n",
        "\n",
        "\n",
        "\n",
        "Label Encoding: maps labels to integers. Good for ordinal.\n",
        "\n",
        "One-Hot Encoding: binary column per category. Good for nominal.\n",
        "\n",
        "Ordinal Encoding: map categories to integers with meaningful order.\n",
        "\n",
        "Target/Mean Encoding, Hashing, Embeddings for high-cardinality or deep-learning use."
      ],
      "metadata": {
        "id": "7PK5B0xsdnv6"
      }
    }
  ]
}